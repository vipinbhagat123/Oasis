{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbec369f",
   "metadata": {},
   "source": [
    "# EMAIL SPAM DETECTION WITH MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd70a51",
   "metadata": {},
   "source": [
    "#### We’ve all been the recipient of spam emails before. Spam mail, or junk mail, is a type of email that is sent to a massive number of users at one time, frequently containing cryptic messages, scams, or most dangerously, phishing content. In this Project, use Python to build an email spam detector. Then, use machine learning to train the spam detector to recognize and classify emails into spam and non-spam. Let’s get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1defcd0a",
   "metadata": {},
   "source": [
    "### Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a3f663a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "messages=pd.read_csv('spam.csv',encoding='ISO-8859-1')\n",
    "messages.rename(columns={'v1':'label','v2':'message'},inplace=True)\n",
    "messages.drop(messages.iloc[:,2:],axis=1,inplace=True)\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30645723",
   "metadata": {},
   "source": [
    "### Data cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "293cb760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer=PorterStemmer()\n",
    "corpus=[]\n",
    "for i in range(0,len(messages)):\n",
    "    review=re.sub('[^a-zA-Z]',' ',messages['message'][i])\n",
    "    review=review.lower()\n",
    "    review=review.split()\n",
    "    \n",
    "    review=[stemmer.stem(word) for word in review if word in stopwords.words('english')]\n",
    "    review=' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd509aca",
   "metadata": {},
   "source": [
    "### Creating the Bag of Words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2aca5d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 129)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer(max_features=5000)\n",
    "X=cv.fit_transform(corpus).toarray()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a9f44a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.get_dummies(messages['label'])\n",
    "y=y.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c1402d",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd10ada2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.20,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d23fcb",
   "metadata": {},
   "source": [
    "### Training model using Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e34d44f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy={}\n",
    "spam_detect_model=MultinomialNB().fit(x_train,y_train)\n",
    "\n",
    "y_pred=spam_detect_model.predict(x_test)\n",
    "a=accuracy_score(y_pred,y_test)\n",
    "accuracy['naive_bayes']=a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcc8f6fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'naive_bayes': 0.9165919282511211}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8471d7b5",
   "metadata": {},
   "source": [
    "### Training model using linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08a2a67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "y_pred = lr.predict(x_test)\n",
    "a = accuracy_score(y_pred,y_test)\n",
    " \n",
    "accuracy['logistic'] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a70c95b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'naive_bayes': 0.9165919282511211, 'logistic': 0.9103139013452914}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d979d73a",
   "metadata": {},
   "source": [
    "### Training model using Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd44b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(x_train,y_train)\n",
    "y_pred = dt.predict(x_test)\n",
    "a = accuracy_score(y_pred,y_test)\n",
    "accuracy['decision_tree'] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4dfae76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'naive_bayes': 0.9165919282511211,\n",
       " 'logistic': 0.9103139013452914,\n",
       " 'decision_tree': 0.9112107623318386}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee7c7f1",
   "metadata": {},
   "source": [
    "### confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f35a122e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[900,  49],\n",
       "       [ 50, 116]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
